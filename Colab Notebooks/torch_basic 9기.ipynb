{"cells":[{"cell_type":"markdown","metadata":{"id":"RzMsP9hsc36l"},"source":["## torch 본격적으로"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1676286918806,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"SAmMX78Lc3Iy","outputId":"fbbe95e7-0130-406c-8687-3b0b50dd6097"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1, 2, 3, 4])\n","<class 'torch.Tensor'>\n","torch.int64\n","torch.Size([4])\n","torch.float32\n","tensor([1.0000, 2.0000, 3.1000, 4.0000])\n"]}],"source":["import torch\n","a=torch.([1,2,3,4])\n","print(a)\n","print(type(a))\n","print(a.dtype) # data type\n","print(a.shape)\n","b=torch.tensor([1,2, 3.1   , 4])\n","print(b.dtype) # 하나라도 실수면 자동으로 실수 타입으로\n","print(b)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":282,"status":"ok","timestamp":1676287166153,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"QRPA6o3EdDy5","outputId":"107d4107-e109-49c1-b02a-36d385709c02"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1, 2, 3],\n","        [3, 4, 5]])\n","torch.Size([2, 3])\n","2\n","6\n"]}],"source":["A=torch.tensor([[1,2,3],[3,4,5]]) # 이 셀부터는 import torch 는 실행 했다 치고 작성\n","# Atorch=.tensor([[1,2],[3,4,5]]) # 리스트와는 달리 이제는 행렬이라서 각 행에 해당하는 숫자의 개수가 같아야 함\n","print(A)\n","print(A.shape)\n","print(A.ndim) # 차원의 수\n","print(A.numel()) # 전체 성분의 수"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":657,"status":"ok","timestamp":1676287339096,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"DtQ20sP8dv8i","outputId":"cb613ed0-202b-4938-c905-92acf12fa690"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0., 0., 0., 0., 0.])\n","tensor([[0, 0, 0],\n","        [0, 0, 0]])\n","tensor([1., 1., 1., 1., 1.])\n","tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]])\n","tensor([3, 5, 7, 9])\n","tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n","        0.9000])\n","tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n","        1.0000])\n"]}],"source":["print(torch.zeros(5))\n","print(torch.zeros_like(A)) # A와 같은 shape의 0으로 채워진 텐서\n","print(torch.ones(5))\n","print(torch.zeros( 3,3 ))\n","print(torch.arange(3,10,2)) # range랑 같은데 tensor로 만들어줌\n","print(torch.arange(0,1,0.1)) # 소수점 가능\n","print(torch.linspace(0,1,10)) # 0 에서부터 1 포함(default) 10개로"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1676287371376,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"mEY_M0PPfRCz","outputId":"ed3645c7-c430-496f-b32b-8b7035e4e244"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([5, 7, 9])\n"]}],"source":["a=torch.tensor([1,2,3])\n","b=torch.tensor([4,5,6])\n","c=a+b\n","print(c)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":283,"status":"ok","timestamp":1676287523601,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"zRGH_ASMfY5q","outputId":"aad09bdd-953a-4948-c248-c03459510f8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[5, 7, 9],\n","        [2, 3, 4]])\n","tensor([[-3, -3, -3],\n","        [ 0,  1,  2]])\n","\n","tensor([[ 4, 10, 18],\n","        [ 1,  2,  3]])\n","tensor([[0.2500, 0.4000, 0.5000],\n","        [1.0000, 2.0000, 3.0000]])\n","tensor([[16, 25, 36],\n","        [ 1,  1,  1]])\n"]}],"source":["A=torch.tensor([[1,2,3],[1,2,3]])\n","B=torch.tensor([[4,5,6],[1,1,1]])\n","C=A+B\n","D=A-B\n","print(C) \n","print(D)\n","print()\n","print(A*B) # 곱셈은? 성분끼리의 곱! (Hadamard product)\n","print(A/B) # 나누기도 마찬가지\n","print(B**2) # 제곱도 각 성분에 대해서 해준다"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1676287784597,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"LDMR3HebgeIS","outputId":"b13395e8-87ce-48ee-eb0c-58ce9cc01548"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 1,  4],\n","        [ 9, 16]])\n","tensor([[ 7, 10],\n","        [15, 22]])\n"]}],"source":["A=torch.tensor([[1,2],[3,4]])\n","B=torch.tensor([[1,2],[3,4]])\n","print(A*B)\n","print(A@B) # 이게 진짜 행렬 곱하기"]},{"cell_type":"markdown","metadata":{"id":"lwIW_G6ThRuW"},"source":["## pytorch 의 인덱싱 슬라이스"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1087,"status":"ok","timestamp":1676287911832,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"EvEXUodtlOyq","outputId":"f13d69c8-4c8b-40cf-80eb-e7de0330243f"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(1)\n","tensor(2)\n","tensor(9)\n","tensor([2, 3, 4])\n","tensor([8, 9])\n","tensor([1, 2, 3, 4, 5, 6, 7])\n","tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n"]}],"source":["a=torch.tensor([1,2,3,4,5,6,7,8,9]) \n","# 인덱싱과 슬라이싱, list할 때와 동일!\n","print(a[0]) \n","print(a[1])\n","print(a[-1])\n","print(a[1:4])\n","print(a[7:])\n","print(a[:7])\n","print(a[:])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1676288477660,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"4PSLeE0flTMC","outputId":"91fd9a8c-8dba-4cf1-d321-29015d1ea596"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1, 2, 3])\n","tensor([7, 8, 9])\n","tensor([[4, 5, 6],\n","        [7, 8, 9]])\n","tensor([[1, 2, 3],\n","        [4, 5, 6],\n","        [7, 8, 9]])\n","tensor(3)\n","tensor(3)\n","[[1, 2, 3, 4], [5, 6, 7, 8]]\n","3\n","tensor([4, 5, 6])\n","tensor([4, 6])\n","tensor([3, 6, 9])\n","tensor([7, 8, 9])\n"]}],"source":["# 행렬에 대한 인덱싱과 슬라이싱\n","A=torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n","print(A[0]) # 하나만 쓰면 행에 대한 인덱싱 (리스트 속 리스트 생각)\n","print(A[-1])\n","print(A[1:])\n","print(A[:])\n","print(A[0][2])\n","print(A[0,2]) # 2차원 행렬도 동일한데, 리스트와 달리 이런 것도 됨\n","B=[[1,2,3,4], [5,6,7,8]]\n","print(B)\n","print(B[0][2])\n","# print(B[0,2]) # error!\n","print(A[1,:]) # 1 행, 전부\n","print(A[1,0:3:2])\n","print(A[:,2]) # 전부, 2 열\n","print(A[:][2])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":299,"status":"ok","timestamp":1676288941791,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"y6Zg1lZ9ZIBe","outputId":"45a4c69a-218b-45fd-e7a4-87873000d56f"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[ 0,  1,  2,  3],\n","         [ 4,  5,  6,  7],\n","         [ 8,  9, 10, 11]],\n","\n","        [[12, 13, 14, 15],\n","         [16, 17, 18, 19],\n","         [20, 21, 22, 23]]])\n","torch.Size([2, 3, 4])\n","tensor(6)\n","torch.Size([1, 1, 4])\n"]}],"source":["# 3차원 행렬 인덱싱\n","A=torch.tensor([ [[0,1,2,3],[4,5,6,7],[8,9,10,11]] ,   \n","                 [[12,13,14,15],[16,17,18,19],[20,21,22,23]] ])\n","print(A)\n","print(A.shape) \n","print(A[0,1,2])\n","\n","a=torch.tensor([[[3,4,5,6]]]) # 대괄호가 하나 늘어나면 왼쪽에 shape 값이 추가 된다.\n","print(a.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1676289862127,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"DBjH6loolzdS","outputId":"b39e4174-bd1c-4f3a-f0b9-dd21253b834c"},"outputs":[{"name":"stdout","output_type":"stream","text":["False\n","tensor([[False, False,  True, False],\n","        [False,  True, False,  True]])\n","tensor([4, 5, 7])\n","tensor([[  1,   2,   3, 100],\n","        [100,   3, 100,   3]])\n","tensor([[1, 2],\n","        [7, 8]])\n","tensor([1, 2])\n"]}],"source":["# boolean 인덱싱\n","a=[1,2,3,4,5,3,3]\n","print(a==3) # 여러개 값 들어있는 리스트랑 3 달랑 하나랑 같냐? 다르다!\n","A=torch.tensor([[1,2,3,4],[5,3,7,3]])\n","print(A==3) # 리스트와 달리 각 성분에 대해 비교해줌\n","print(A[A>3]) # True, False가 담긴 행렬로 인덱싱 가능!!\n","\n","A[A>3] = 100\n","print(A) # 그러면 이런 것도 가능하다! (3보다 큰애들을 100으로 바꿔줘)\n","\n","A=torch.tensor([[1,2],[3,4],[5,6],[7,8]])\n","B=torch.tensor([True, False, False, True]) # 참고로 그냥 리스트여도 됨\n","print(A[B,:]) # 0행, 3행 슬라이싱\n","\n","b=torch.tensor([1,2,3,4])\n","print(b[[True,True,False,False]])\n","c=[1,2,3,4]\n","# c[[True,True,False,False]] # error!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":505,"status":"ok","timestamp":1676290385847,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"FzKn6wIJZAgn","outputId":"5d13217a-9951-4d8a-b4cb-8fbcf32e2211"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(3)\n","tensor(3)\n","tensor([3, 4, 5])\n","tensor([[3, 3, 3],\n","        [4, 4, 4]])\n","tensor([1, 2, 3])\n","torch.Size([2, 2, 3])\n","tensor([[[1, 2, 3],\n","         [4, 5, 6]],\n","\n","        [[4, 5, 6],\n","         [4, 5, 6]]])\n"]}],"source":["# tensor로 인덱싱\n","a=torch.tensor([1,2,3,4,5])\n","A=a[2]\n","print(A)\n","A=a[ torch.tensor(2) ] # torch.tensor 안에다가?\n","print(A)\n","A=a[ torch.tensor([2,3,4]) ]\n","print(A)\n","A=a[ torch.tensor([[2,2,2],[3,3,3]]) ]\n","print(A) # 인덱싱된 애들로 2행 3열짜리 행렬을 만든다\n","\n","a=[1,2,3]\n","# a[ [1,1,1,1,2,2,2] ] # error!\n","\n","a=torch.tensor([[1,2,3],[4,5,6]])\n","print(a[0])\n","A=a[ torch.tensor([[0,1],[1,1]]) ]\n","print(A.shape) # 예를 들어, a[0] = tensor([1,2,3])과 같이 1차원 데이터이므로 한 차원이 뒤에 늘어나서 2,2, \"3\" 이 된다!\n","print(A) # segmentation 결과 그림 보여줄 때 사용!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":249,"status":"ok","timestamp":1676290526679,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"BBEF3i6xl1sK","outputId":"70213f8d-7355-4795-ed20-3e13c9d8ef75"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1, 2],\n","        [3, 4],\n","        [5, 6],\n","        [7, 8]])\n","torch.Size([4, 2])\n","tensor(2)\n","tensor([2])\n","tensor([2])\n","tensor([2])\n","tensor([[3, 4],\n","        [3, 4],\n","        [5, 6],\n","        [5, 6],\n","        [5, 6]])\n"]}],"source":["A=torch.tensor([[1,2],[3,4],[5,6],[7,8]])\n","print(A)\n","print(A.shape)\n","\n","# 1. A[몇 번째 행이냐, 몇 번째 열이냐]\n","print(A[0,1])\n","# 2. A[ tensor(bool) ] => A와 같은 shape을 가지는 tensor형 bool이 어디에 True를 가지고 있냐\n","print(A[ torch.tensor([[False,True],[False,False],[False,False],[False,False]]) ])\n","print(A[A==2])\n","# 3. A[몇 번째 값에 True가 있냐, 몇 번째 값에 True가 있냐]\n","print(A[ [True,False,False,False], [False,True] ])\n","# 4. A[ tensor ] # 몇 번째 것을 어떻게 쌓을거냐\n","print(A[ torch.tensor([1,1,2,2,2]) ])"]},{"cell_type":"markdown","metadata":{"id":"QYBXKfCupHU9"},"source":["## pytorch의 여러 함수들"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":299,"status":"ok","timestamp":1676290702255,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"0lfFqRGOpI-0","outputId":"df742c95-7708-4b68-ec4e-92306cff22ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-1.4740, -0.1145, -0.2977],\n","        [ 0.7295,  0.1686, -0.0496],\n","        [ 0.9012, -0.6210, -1.3800]])\n","tensor([[0.9141, 0.6691, 0.0333],\n","        [0.3754, 0.6951, 0.4863],\n","        [0.3543, 0.9568, 0.4791]])\n","tensor([[-1.4740, -0.1145, -0.2977]])\n"]}],"source":["A=torch.randn(3,3) # Normal의 n\n","B=torch.rand(3,3) # 이건 uniform\n","print(A)\n","print(B)\n","print(A[A[:,0]<0,:]) # 0 번째 열이 음수인 행들"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1676290990896,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"J6KxUXALpniU","outputId":"f7f90117-bdd8-4649-8303-11e85d072318"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0.9608,  0.8523, -0.6820],\n","        [ 1.3323,  0.5321, -1.2132],\n","        [-0.3762, -0.8956, -0.8966]])\n","tensor([[0.9608, 0.8523, 0.6820],\n","        [1.3323, 0.5321, 1.2132],\n","        [0.3762, 0.8956, 0.8966]])\n","tensor([[0.9802, 0.9232, 0.8258],\n","        [1.1542, 0.7294, 1.1014],\n","        [0.6134, 0.9464, 0.9469]])\n","tensor([[2.6139, 2.3450, 0.5056],\n","        [3.7896, 1.7025, 0.2973],\n","        [0.6865, 0.4083, 0.4079]])\n","tensor([[-0.0399, -0.1599, -0.3827],\n","        [ 0.2869, -0.6310,  0.1932],\n","        [-0.9776, -0.1102, -0.1091]])\n","tensor(1.)\n","tensor(1.)\n","tensor(1.)\n","tensor([[ 1.,  1., -1.],\n","        [ 1.,  1., -1.],\n","        [-0., -1., -1.]])\n","tensor([[ 0.9600,  0.8500, -0.6800],\n","        [ 1.3300,  0.5300, -1.2100],\n","        [-0.3800, -0.9000, -0.9000]])\n","tensor([[ 0.,  0., -1.],\n","        [ 1.,  0., -2.],\n","        [-1., -1., -1.]])\n","tensor([[ 1.,  1., -0.],\n","        [ 2.,  1., -1.],\n","        [-0., -0., -0.]])\n"]}],"source":["A=torch.randn(3,3)\n","print(A)\n","print(torch.abs(A))\n","print(torch.sqrt(torch.abs(A)))\n","print(torch.exp(A))\n","print(torch.log(torch.abs(A)))\n","print(torch.log(torch.exp(torch.tensor(1)))) # torch.exp(torch.tensor(1)) = e^1   #주의! torch.exp(1) = error!\n","print(torch.log10(torch.tensor(10)))\n","print(torch.log2(torch.tensor(2)))\n","print(torch.round(A)) # 반올림\n","print(torch.round(A, decimals=2)) # 소수점 둘째자리까지\n","print(torch.floor(A)) # 내림\n","print(torch.ceil(A)) # 올림"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":430,"status":"ok","timestamp":1676291106717,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"PFPjWX54qaXi","outputId":"9fb14a48-0eb1-45b0-e2b8-40f483fc22e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(0.5000)\n","tensor(0.5000)\n","tensor(1.)\n","tensor(-1.)\n"]},{"data":{"text/plain":["torch.Tensor"]},"execution_count":112,"metadata":{},"output_type":"execute_result"}],"source":["print(torch.sin(torch.tensor(torch.pi/6))) # type(torch.pi) <- 토치 파이는 float이지만, 만약 tensor와 연산하면 tensor로 바꿔줌\n","print(torch.cos(torch.tensor(torch.pi/3)))\n","print(torch.tan(torch.tensor(torch.pi/4)))\n","print(torch.tanh(torch.tensor(-10)))\n","\n","type(torch.tensor(1)/6)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["import torch\n","\n","type(torch.pi)\n","torch.log(torch.tensor(1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":258,"status":"ok","timestamp":1676291158174,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"huDfIsJoqdDa","outputId":"07acf8c6-c2c9-4709-baa5-97fbc1c94e1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([False, False,  True, False, False])\n","tensor([False, False, False, False,  True])\n"]}],"source":["torch.nan # not a number\n","torch.log(torch.tensor(-1))\n","print(torch.isnan(torch.tensor([1,2,torch.nan,3,4])))\n","print(torch.isinf(torch.tensor([1,2,3,4,torch.inf])))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1676291412167,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"C9G0Rdhiqn3a","outputId":"802fde76-1610-402a-b311-6c5d16d84ba4"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 1.5816, -0.9170, -1.8009,  1.7364],\n","        [ 1.0022, -0.1015, -0.2307,  1.9819],\n","        [ 0.6689,  1.4289, -0.8728,  0.4382]])\n","tensor(1.9819)\n","torch.return_types.max(\n","values=tensor([ 1.5816,  1.4289, -0.2307,  1.9819]),\n","indices=tensor([0, 2, 1, 1]))\n","torch.return_types.max(\n","values=tensor([1.7364, 1.9819, 1.4289]),\n","indices=tensor([3, 3, 1]))\n","torch.return_types.max(\n","values=tensor([[ 1.5816,  1.4289, -0.2307,  1.9819]]),\n","indices=tensor([[0, 2, 1, 1]]))\n","torch.return_types.max(\n","values=tensor([[1.7364],\n","        [1.9819],\n","        [1.4289]]),\n","indices=tensor([[3],\n","        [3],\n","        [1]]))\n","tensor(-1.8009)\n","torch.return_types.min(\n","values=tensor([ 0.6689, -0.9170, -1.8009,  0.4382]),\n","indices=tensor([2, 0, 0, 2]))\n","torch.return_types.min(\n","values=tensor([-1.8009, -0.2307, -0.8728]),\n","indices=tensor([2, 2, 2]))\n","tensor(7)\n","tensor([0, 2, 1, 1])\n","tensor([3, 3, 1])\n"]}],"source":["A=torch.randn(3,4)\n","print(A)\n","print(torch.max(A))\n","print(torch.max(A,dim=0))\n","print(torch.max(A,dim=1)) # 1D array로 바꿔버림\n","print(torch.max(A,dim=0, keepdims=True))\n","print(torch.max(A,dim=1, keepdims=True)) # 3 행 1열 짜리 2D tensor\n","print(torch.min(A))\n","print(torch.min(A,dim=0))\n","print(torch.min(A,dim=1))\n","print(torch.argmax(A))\n","print(torch.argmax(A,dim=0)) # 각 열에서 가장 큰 애가 존재하는 인덱스\n","print(torch.argmax(A,dim=1)) # 각 행에서 가장 큰 애가 존재하는 인덱스"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1676291596870,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"5h8JeQ8bqsrv","outputId":"e459147d-3a1b-499b-cc3f-55d58fcd2759"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-0.9172],\n","        [-0.3115],\n","        [ 1.2793],\n","        [-0.3870],\n","        [-0.2347],\n","        [ 0.3376]])\n","torch.return_types.sort(\n","values=tensor([[-0.9172],\n","        [-0.3870],\n","        [-0.3115],\n","        [-0.2347],\n","        [ 0.3376],\n","        [ 1.2793]]),\n","indices=tensor([[0],\n","        [3],\n","        [1],\n","        [4],\n","        [5],\n","        [2]]))\n","torch.return_types.sort(\n","values=tensor([[-2.7196],\n","        [-0.5565],\n","        [-0.4622],\n","        [-0.4303],\n","        [-0.3988],\n","        [-0.1039]]),\n","indices=tensor([[4],\n","        [5],\n","        [2],\n","        [3],\n","        [0],\n","        [1]]))\n","torch.return_types.sort(\n","values=tensor([[-0.1039],\n","        [-0.3988],\n","        [-0.4303],\n","        [-0.4622],\n","        [-0.5565],\n","        [-2.7196]]),\n","indices=tensor([[1],\n","        [0],\n","        [3],\n","        [2],\n","        [5],\n","        [4]]))\n","tensor(-0.1039)\n","tensor(-0.1039)\n","tensor([[0.3988],\n","        [0.1039],\n","        [0.4622],\n","        [0.4303],\n","        [2.7196],\n","        [0.5565]])\n","tensor([[0.3988],\n","        [0.1039],\n","        [0.4622],\n","        [0.4303],\n","        [2.7196],\n","        [0.5565]])\n"]}],"source":["a=torch.randn(6,1)\n","print(a)\n","a_sorted=torch.sort(a,dim=0)\n","print(a_sorted)\n","\n","a=torch.randn(6,1)\n","print(a.sort(dim=0))\n","print(a.sort(dim=0, descending=True))\n","\n","print(torch.max(a))\n","print(a.max())\n","print(torch.abs(a))\n","print(a.abs())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1676291654862,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"KJUEZtB4rglS","outputId":"8abd7935-ac40-4858-f6c3-f5755fa6c119"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-1.6230e+00,  1.2844e+00,  1.1063e+00,  3.7231e-01],\n","        [-4.0481e-01,  6.5913e-01,  8.8628e-04, -9.0618e-01],\n","        [ 2.0323e-01,  1.3782e+00,  2.1957e+00,  9.1018e-01]])\n","tensor(5.1764)\n","tensor([ 1.1400, -0.6510,  4.6873])\n","tensor([[ 1.1400],\n","        [-0.6510],\n","        [ 4.6873]])\n","tensor(0.4314)\n","tensor([ 0.2850, -0.1627,  1.1718])\n","tensor([[ 0.2850],\n","        [-0.1627],\n","        [ 1.1718]])\n","tensor(1.0627)\n","tensor([[ 1.1400],\n","        [-0.6510],\n","        [ 4.6873]])\n","tensor([[ 0.2850],\n","        [-0.1627],\n","        [ 1.1718]])\n","tensor(1.0627)\n"]}],"source":["A=torch.randn(3,4)\n","print(A)\n","print(torch.sum(A))\n","print(torch.sum(A,dim=1))\n","print(torch.sum(A,dim=1,keepdims=True))\n","print(torch.mean(A))\n","print(torch.mean(A,dim=1))\n","print(torch.mean(A,dim=1,keepdims=True))\n","print(torch.std(A)) # standard deviation 표준 편차\n","\n","print(A.sum(dim=1, keepdims=True))\n","print(A.mean(dim=1, keepdims=True))\n","print(A.std())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1676291705887,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"CmuensVlsERE","outputId":"540123f7-723c-4d53-b685-0c743a849bca"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1, 3, 4, 4, 3, 2, 2, 2, 3, 4, 3, 2])\n","torch.Size([12])\n","tensor([[[1, 3, 4],\n","         [4, 3, 2]],\n","\n","        [[2, 2, 3],\n","         [4, 3, 2]]])\n","3\n"]}],"source":["A=torch.randint(1,5,size=(12,)) # 1부터 5미만 12개 정수 (1 차원은 (N,) 과 같이 표현)\n","print(A)\n","print(A.shape)\n","\n","B=A.reshape(2,2,3)\n","print(B)\n","print(B.ndim) # 3 차원 행렬이다"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":306,"status":"ok","timestamp":1676291942658,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"VdXu_OZ1sgNK","outputId":"b6c0f27b-5b9a-4818-e73a-a3a5ab79d642"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(9)\n","tensor([[9]])\n","tensor([[9]])\n","tensor([[9]])\n","tensor([[9]])\n","torch.Size([4, 6, 3])\n"]}],"source":["a=torch.tensor([1,2,3])\n","b=torch.tensor([2,2,1])\n","print(torch.sum(a*b))\n","\n","a=a.reshape(3,1)\n","b=b.reshape(3,1)\n","print(a.transpose(1,0)@b)\n","print(a.permute(1,0)@b) # permute가 더 좋다 왜 ? transpose는 2차원 행렬만 가능하지만, permute는 2차원 이상의 행렬도 가능하다\n","print(a.T@b)\n","print(a.t()@b)\n","\n","A=torch.randn(4,3,6)\n","print(A.permute(0,2,1).shape) # 4,6,3\n","\n","# 참고\n","# transpose 의 경우에는 그냥 순서 상관없이 두개만 바꿔주면 된다\n","# permute 의 경우에는 순서를 바꿔주는 것이다\n","# 예를 들어\n","# A=torch.randn(4,3,6)\n","# print(A.permute(0,2,1).shape) # 4,6,3\n","# print(A.permute(0,1,2).shape) # 4,3,6\n","# print(A.permute(2,1,0).shape) # 6,3,4\n","# print(A.permute(2,0,1).shape) # 6,4,3\n","# print(A.permute(1,0,2).shape) # 3,4,6\n","# transpose 의 경우에는\n","# print(A.transpose(0,1).shape) # 3,4,6\n","# print(A.transpose(0,2).shape) # 6,3,4\n","# print(A.transpose(1,2).shape) # 4,6,3\n","# print(A.transpose(1,0).shape) # 3,4,6\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":771,"status":"ok","timestamp":1676292032249,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"aYsTsVD7sjmj","outputId":"94f9f905-c569-4876-f8fc-f222c0f09007"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n","        18, 19])\n","tensor([[ 0,  1,  2,  3,  4],\n","        [ 5,  6,  7,  8,  9],\n","        [10, 11, 12, 13, 14],\n","        [15, 16, 17, 18, 19]])\n","torch.Size([4, 5])\n","torch.Size([2, 5, 2])\n","torch.Size([2, 2, 5])\n","torch.Size([1, 20])\n","torch.Size([20, 1])\n"]}],"source":["A=torch.arange(20)\n","print(A)\n","print(A.reshape(4,5))\n","print(A.reshape(4,-1).shape) # 4개 행이 될 수 있도록 열의 수를 맞춰라\n","print(A.reshape(2,5,-1).shape)\n","print(A.reshape(2,-1,5).shape)\n","print(A.reshape(1,-1).shape) # 2차원 행 벡터\n","print(A.reshape(-1,1).shape) # 2차원 열 벡터"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":283,"status":"ok","timestamp":1676292079096,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"VFBBHxp2zFyr","outputId":"39a20a97-b7ff-4185-d1c2-10290014805d"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([4, 5, 6])\n","torch.Size([4, 5, 6])\n","torch.Size([2, 3, 4, 5])\n","torch.Size([2, 3, 4, 5])\n","torch.Size([3, 4, 6])\n","torch.Size([3, 4, 6])\n"]}],"source":["x=torch.randn(2,3,4,5,6)\n","print(x[1,2,:,:,:].shape) \n","print(x[1,2,...].shape) # x[1, 2, …] 는 x[1, 2, :, :, :] 와 같습니다.\n","print(x[:,:,:,:,3].shape)\n","print(x[...,3].shape) # x[…, 3] 는 x[:, :, :, :, 3] 와 같습니다.\n","print(x[1,:,:,3,:].shape)\n","print(x[1,...,3,:].shape) # x[1, …, 3, :] 는 x[1, :, :, 3, :] 와 같습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1676292372714,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"VsBKRAiJzbBz","outputId":"52d19d04-bacf-4c4c-919f-667e3a7e3bf4"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 1., 1., 1.],\n","        [1., 1., 1., 1.],\n","        [1., 1., 1., 1.],\n","        [0., 0., 0., 0.],\n","        [0., 0., 0., 0.],\n","        [0., 0., 0., 0.]])\n","tensor([[1., 1., 1., 1., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 0., 0., 0., 0.]])\n","tensor([[1., 1., 1., 1.],\n","        [1., 1., 1., 1.],\n","        [1., 1., 1., 1.],\n","        [0., 0., 0., 0.],\n","        [0., 0., 0., 0.],\n","        [0., 0., 0., 0.]])\n","tensor([[1., 1., 1., 1., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 0., 0., 0., 0.]])\n"]}],"source":["A=torch.ones(3,4)\n","B=torch.zeros(3,4)\n","C=torch.vstack([A,B]) \n","D=torch.hstack([A,B]) # v는 0번째 차원, h는 1번째 차원에 쌓는다. (A,B 사이즈 (2,3,4)로 추가 해보기) 가급적 3차 이상의 텐서에는 사용하지 않는 것이 좋다\n","E=torch.cat([A,B], dim=0)\n","F=torch.cat([A,B], dim=1)\n","# G=torch.cat([A,B], dim=2)\n","\n","print(C)\n","print(D)\n","print(E)\n","print(F)\n","# print(G)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1676292428619,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"EOsKnQTvzeAL","outputId":"60b3cef4-3a4b-4584-c054-eac4133624e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[[[[[[ 0.2950],\n","              [-0.7118],\n","              [ 0.2723],\n","              [-0.0418]]]],\n","\n","\n","\n","           [[[[ 0.0845],\n","              [-0.4334],\n","              [ 0.3632],\n","              [ 1.0408]]]],\n","\n","\n","\n","           [[[[-0.5292],\n","              [ 1.9320],\n","              [ 1.3440],\n","              [-0.7689]]]]]]]])\n","torch.Size([1, 1, 1, 3, 1, 1, 4, 1])\n","torch.Size([3, 4])\n"]}],"source":["A = torch.randn(1,1,1,3,1,1,4,1)\n","print(A)\n","print(A.shape)\n","print(A.squeeze().shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1676292687236,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"fgFgG48p02YK","outputId":"487b2b78-00a8-467e-f26b-889e0715fd80"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 3, 4])\n","torch.Size([3, 1, 4])\n","torch.Size([3, 4, 1])\n","torch.Size([1, 3, 4])\n","torch.Size([3, 1, 4])\n","torch.Size([3, 4, 1])\n"]}],"source":["A = torch.randn(3,4)\n","print(A.unsqueeze(dim=0).shape)\n","print(A.unsqueeze(dim=1).shape)\n","print(A.unsqueeze(dim=2).shape)\n","print(A.reshape(1,3,4).shape)\n","print(A.reshape(3,1,4).shape)\n","print(A.reshape(3,4,1).shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1676293475994,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"z5mTHp5x1IC7","outputId":"fa814a31-57cb-44a8-ad32-ffd3d21ef700"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.]],\n","\n","        [[0., 0., 0., 0.],\n","         [0., 0., 0., 0.],\n","         [0., 0., 0., 0.]]])\n","torch.Size([2, 3, 4])\n"]}],"source":["# 사용법 : 채널 쪽으로 차원을 추가하고 싶을 때 아래의 코드를 사용하면 된다\n","A=torch.ones(3,4)\n","B=torch.zeros(3,4)\n","A=A.unsqueeze(dim=0)\n","B=B.unsqueeze(dim=0)\n","C=torch.cat([A,B], dim=0)\n","print(C)\n","print(C.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1676293535777,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"jQmtU9_04IrE","outputId":"bef0cc52-4c52-4f80-c3ec-a203eac84e01"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[100,   2],\n","        [  3,   4]])\n","tensor([[1, 2],\n","        [3, 4]])\n"]}],"source":["A=torch.tensor([[1,2],[3,4]])\n","B=A.clone()\n","B[0,0]=100\n","\n","print(B)\n","print(A)"]},{"cell_type":"markdown","metadata":{"id":"ZzGmCjXL4ZGX"},"source":["## @ 에 대해 좀만 더"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1676294096020,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"gBSE3Nmb4bcd","outputId":"7d382d17-8e64-411f-9efc-8d5b55d9aabb"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([5, 10])\n","torch.Size([32, 5, 10])\n"]}],"source":["A=torch.randn(5,7)\n","B=torch.randn(7,10)\n","C=A@B\n","print(C.shape)\n","\n","A=torch.randn(32,5,7)\n","B=torch.randn(32,7,10)\n","C=A@B\n","print(C.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1676294096021,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"1Tfwc16c5cEa","outputId":"9eb1ef76-c5bb-410b-cc47-60cb0b0d4488"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([32, 5, 10])\n","torch.Size([32, 5, 10])\n","tensor(9.5367e-07)\n"]}],"source":["A=torch.randn(32,5,7)\n","B=torch.randn(7,10)\n","\n","C=A@B.repeat(32,1,1)\n","D=A@B\n","\n","print(C.shape)\n","print(D.shape)\n","print((C-D).abs().max())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1676294136562,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"wNCOOund6d3O","outputId":"e41cd41e-ab61-4002-d6f6-39f4c6216197"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0.4890, 0.1937, 0.3766],\n","        [0.7003, 0.3296, 0.5333]])\n","tensor([[[[0.4890, 0.1937, 0.3766, 0.4890, 0.1937, 0.3766],\n","          [0.7003, 0.3296, 0.5333, 0.7003, 0.3296, 0.5333],\n","          [0.4890, 0.1937, 0.3766, 0.4890, 0.1937, 0.3766],\n","          [0.7003, 0.3296, 0.5333, 0.7003, 0.3296, 0.5333],\n","          [0.4890, 0.1937, 0.3766, 0.4890, 0.1937, 0.3766],\n","          [0.7003, 0.3296, 0.5333, 0.7003, 0.3296, 0.5333]]],\n","\n","\n","        [[[0.4890, 0.1937, 0.3766, 0.4890, 0.1937, 0.3766],\n","          [0.7003, 0.3296, 0.5333, 0.7003, 0.3296, 0.5333],\n","          [0.4890, 0.1937, 0.3766, 0.4890, 0.1937, 0.3766],\n","          [0.7003, 0.3296, 0.5333, 0.7003, 0.3296, 0.5333],\n","          [0.4890, 0.1937, 0.3766, 0.4890, 0.1937, 0.3766],\n","          [0.7003, 0.3296, 0.5333, 0.7003, 0.3296, 0.5333]]],\n","\n","\n","        [[[0.4890, 0.1937, 0.3766, 0.4890, 0.1937, 0.3766],\n","          [0.7003, 0.3296, 0.5333, 0.7003, 0.3296, 0.5333],\n","          [0.4890, 0.1937, 0.3766, 0.4890, 0.1937, 0.3766],\n","          [0.7003, 0.3296, 0.5333, 0.7003, 0.3296, 0.5333],\n","          [0.4890, 0.1937, 0.3766, 0.4890, 0.1937, 0.3766],\n","          [0.7003, 0.3296, 0.5333, 0.7003, 0.3296, 0.5333]]]])\n","torch.Size([3, 1, 6, 6])\n"]}],"source":["A = torch.rand(2,3)\n","A_repeat=A.repeat(3,1,3,2)\n","print(A)\n","print(A_repeat)\n","print(A_repeat.shape)"]},{"cell_type":"markdown","metadata":{"id":"bOWfXx3R7Llb"},"source":["## numpy <-> torch 왔다갔다 가능"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":406,"status":"ok","timestamp":1676294376980,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"a6jgGeti7OLU","outputId":"e7d1dbfa-a034-4986-d519-0b3fc1095e3c"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'torch.Tensor'>\n","<class 'numpy.ndarray'>\n"]}],"source":["import numpy as np\n","import torch\n","\n","a=np.array([1,2,3])\n","b=torch.tensor([1,2,3])\n","A=torch.tensor(a) # A=torch.from_numpy(a)\n","B=b.numpy() # B=np.array(b)\n","print(type(A))\n","print(type(B))"]},{"cell_type":"markdown","metadata":{"id":"TKFUIaQi7lZr"},"source":["## 딥러닝을 가능케한 autograd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1676294508996,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"DJYErqIP7kiO","outputId":"ec156131-8ed4-4029-dc6e-f3757987d4d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1.], requires_grad=True)\n"]}],"source":["x = torch.tensor([1.], requires_grad=True) # float 이여야해서 1.\n","print(x)\n","\n","# 나 x로 미분할 준비 하겠다!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1676294561081,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"S2Di_ifA8E3b","outputId":"2db24355-e04a-4cc4-a56c-a1d5695bd738"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1.])\n","False\n","tensor([1.], requires_grad=True)\n","True\n"]}],"source":["x = torch.tensor([1.])\n","print(x)\n","print(x.requires_grad)\n","\n","x.requires_grad=True\n","print(x)\n","print(x.requires_grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":525,"status":"ok","timestamp":1676294763936,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"mZ554C4-8Rl8","outputId":"b6914778-fa11-486c-9caa-fba35eff8f87"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1.], grad_fn=<PowBackward0>)\n","None\n","tensor([2.])\n"]}],"source":["x = torch.tensor([1.], requires_grad=True)\n","y = x**2\n","print(y) # PowBackward0 가 붙어있다!\n","\n","print(x.grad)\n","y.backward()\n","print(x.grad) # y=x**2을 미분한 2x의 x 값에 1을 대입한 gradient 값"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1676295436183,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"ttcA0ZFr9DCa","outputId":"1023f12c-46a1-4ab3-e323-dad01094defa"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1.], grad_fn=<PowBackward0>)\n","tensor([3.], grad_fn=<MulBackward0>)\n","tensor([6.])\n"]}],"source":["x = torch.tensor([1.], requires_grad=True)\n","y = x**2\n","print(y)\n","y.retain_grad() # 이걸 하면 y.grad도 볼 수 있다\n","\n","z = 3*y\n","print(z) # MulBackward0 가 붙어있다\n","\n","z.backward()\n","print(x.grad) # chain rule로 알아냄\n","# print(y.grad) # warning! 중간건 안된다"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":489,"status":"ok","timestamp":1676295444629,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"R4wTmgrN-1Q1","outputId":"4658c634-c307-4da4-a154-ded882af3ee1"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([2.])\n"]}],"source":["x = torch.tensor([1.], requires_grad=True)\n","y = x**2\n","z = 3*y\n","\n","y.backward() # 이렇게하면 y에서부터 뒤로 넘어감 (backward!)\n","print(x.grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1676295741743,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"-mrlBKDK_nq6","outputId":"c6df4ab3-7faf-4374-96a7-d62213dac6db"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([2.], grad_fn=<AddBackward0>)\n","tensor([8.])\n"]}],"source":["x = torch.tensor([1.], requires_grad=True)\n","a = x**2\n","b = a+1\n","print(b) # AddBackward0 가 붙어있다.\n","c=b**2\n","c.backward()\n","print(x.grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1676295831086,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"Pus5_HLHARxr","outputId":"2d98cc0e-c545-4bf3-a2ec-4bc19c32b08e"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([3.], grad_fn=<AddBackward0>)\n","tensor([4.])\n","tensor([2.])\n"]}],"source":["x=torch.tensor([1.],requires_grad=True)\n","y=torch.tensor([1.],requires_grad=True)\n","z= 2*x**2 + y**2\n","print(z)\n","z.backward()\n","print(x.grad)\n","print(y.grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1676295885713,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"qfjRrQaDBHrO","outputId":"96ebf2e0-b993-4301-dac5-5050205faaa0"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([2.])\n","tensor([1.])\n"]}],"source":["x=torch.tensor([1.],requires_grad=True)\n","y=torch.tensor([1.],requires_grad=True)\n","z= y*x**2\n","z.backward()\n","print(x.grad)\n","print(y.grad)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1676295947579,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"WnPC62D2BVDT","outputId":"d04ee7c5-8a51-4e0c-d061-cc2e50d01aa3"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(14., grad_fn=<SumBackward0>)\n","tensor([2., 4., 6.])\n"]}],"source":["x=torch.tensor([1., 2., 3.] ,requires_grad=True)\n","y=torch.sum(x**2) # x1**2 + x2**2 + x3**2\n","y.backward()\n","\n","print(y)\n","print(x.grad) # 스칼라를 벡터로 미분"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":281,"status":"ok","timestamp":1676296009629,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"Q9WcXWrsBj8q","outputId":"fae66cf7-d78f-46ff-a29b-a837287d4139"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1.])\n"]}],"source":["x=torch.tensor([1.] ,requires_grad=True)\n","x.requires_grad=False \n","# tranfer learning 할 때 필요\n","y=x**2\n","print(y)\n","# y.backward() # error!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":341,"status":"ok","timestamp":1676296057406,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"toLe0766Bsdq","outputId":"aeeaed1f-76f1-4608-fc17-86b7a90784e4"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([2.])\n","tensor([4.])\n"]}],"source":["x=torch.tensor([2.] ,requires_grad=True)\n","x=x.detach() # detach도 많이 쓰이는 듯\n","print(x)\n","y=x**2\n","print(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":360,"status":"ok","timestamp":1676296284876,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"CX8bmRudB3vN","outputId":"f82717ee-6bb1-4350-d2e2-15d1d9f62b55"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","tensor([1.])\n","True\n","tensor([1.], grad_fn=<PowBackward0>)\n","False\n","tensor([1.])\n"]}],"source":["# detach 와 torch.no_grad\n","x=torch.tensor([1.], requires_grad=True)\n","# chain rule을 위해 계속 grad_fn을 update 하니까 grad_fn 잠시 안 계산하고 싶을 때 torch.no_grad\n","# 모델 테스트 시에는 불필요하게 메모리 쓸 필요 없기 때문!\n","with torch.no_grad(): \n","    y = x**2\n","    print(x.requires_grad)\n","    print(y) # with 안에서 계산되는 애는 grad_fn 이 안붙음\n","    # 즉 연산 자체는 하되 grad_fn라는 attribute가 안 붙음\n","print(x.requires_grad)\n","# y.backward() # error! # 즉 여기선 에러가 당연히 뜨겠지. with 안에서 계산된 애들은 grad_fn이 안 붙었으니까\n","y=x**2\n","print(y)\n","\n","x=torch.tensor([1.], requires_grad=True)\n","x=x.detach() # detach는 계산은 하되 grad_fn이 붙지 않음. 즉 torch.no_grad 와 비슷\n","y = x**2\n","print(x.requires_grad)\n","print(y)\n","# y.backward() # error!"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":454},"executionInfo":{"elapsed":497,"status":"ok","timestamp":1676296620550,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"4Q7Ty0laC2Ua","outputId":"f18e8ff4-5b7c-4a9c-a6e7-436b32adb392"},"outputs":[{"ename":"ExecutableNotFound","evalue":"failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m~/opt/anaconda3/envs/torch_py39/lib/python3.9/site-packages/graphviz/backend/execute.py:79\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m         kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mPIPE\n\u001b[0;32m---> 79\u001b[0m     proc \u001b[39m=\u001b[39m _run_input_lines(cmd, input_lines, kwargs\u001b[39m=\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39melse\u001b[39;00m:\n","File \u001b[0;32m~/opt/anaconda3/envs/torch_py39/lib/python3.9/site-packages/graphviz/backend/execute.py:99\u001b[0m, in \u001b[0;36m_run_input_lines\u001b[0;34m(cmd, input_lines, kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_input_lines\u001b[39m(cmd, input_lines, \u001b[39m*\u001b[39m, kwargs):\n\u001b[0;32m---> 99\u001b[0m     popen \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mPopen(cmd, stdin\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    101\u001b[0m     stdin_write \u001b[39m=\u001b[39m popen\u001b[39m.\u001b[39mstdin\u001b[39m.\u001b[39mwrite\n","File \u001b[0;32m~/opt/anaconda3/envs/torch_py39/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[1;32m    952\u001b[0m                         pass_fds, cwd, env,\n\u001b[1;32m    953\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[1;32m    954\u001b[0m                         p2cread, p2cwrite,\n\u001b[1;32m    955\u001b[0m                         c2pread, c2pwrite,\n\u001b[1;32m    956\u001b[0m                         errread, errwrite,\n\u001b[1;32m    957\u001b[0m                         restore_signals,\n\u001b[1;32m    958\u001b[0m                         gid, gids, uid, umask,\n\u001b[1;32m    959\u001b[0m                         start_new_session)\n\u001b[1;32m    960\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n","File \u001b[0;32m~/opt/anaconda3/envs/torch_py39/lib/python3.9/subprocess.py:1821\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1820\u001b[0m         err_msg \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1821\u001b[0m     \u001b[39mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1822\u001b[0m \u001b[39mraise\u001b[39;00m child_exception_type(err_msg)\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: PosixPath('dot')","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)","File \u001b[0;32m~/opt/anaconda3/envs/torch_py39/lib/python3.9/site-packages/IPython/core/formatters.py:972\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    969\u001b[0m     method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n\u001b[1;32m    971\u001b[0m     \u001b[39mif\u001b[39;00m method \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 972\u001b[0m         \u001b[39mreturn\u001b[39;00m method(include\u001b[39m=\u001b[39;49minclude, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[1;32m    973\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[39melse\u001b[39;00m:\n","File \u001b[0;32m~/opt/anaconda3/envs/torch_py39/lib/python3.9/site-packages/graphviz/jupyter_integration.py:98\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_mimebundle_\u001b[0;34m(self, include, exclude, **_)\u001b[0m\n\u001b[1;32m     96\u001b[0m include \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(include) \u001b[39mif\u001b[39;00m include \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jupyter_mimetype}\n\u001b[1;32m     97\u001b[0m include \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(exclude \u001b[39mor\u001b[39;00m [])\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m {mimetype: \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method_name)()\n\u001b[1;32m     99\u001b[0m         \u001b[39mfor\u001b[39;00m mimetype, method_name \u001b[39min\u001b[39;00m MIME_TYPES\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    100\u001b[0m         \u001b[39mif\u001b[39;00m mimetype \u001b[39min\u001b[39;00m include}\n","File \u001b[0;32m~/opt/anaconda3/envs/torch_py39/lib/python3.9/site-packages/graphviz/jupyter_integration.py:98\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     96\u001b[0m include \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(include) \u001b[39mif\u001b[39;00m include \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jupyter_mimetype}\n\u001b[1;32m     97\u001b[0m include \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(exclude \u001b[39mor\u001b[39;00m [])\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m {mimetype: \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, method_name)()\n\u001b[1;32m     99\u001b[0m         \u001b[39mfor\u001b[39;00m mimetype, method_name \u001b[39min\u001b[39;00m MIME_TYPES\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    100\u001b[0m         \u001b[39mif\u001b[39;00m mimetype \u001b[39min\u001b[39;00m include}\n","File \u001b[0;32m~/opt/anaconda3/envs/torch_py39/lib/python3.9/site-packages/graphviz/jupyter_integration.py:112\u001b[0m, in \u001b[0;36mJupyterIntegration._repr_image_svg_xml\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_repr_image_svg_xml\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    111\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the rendered graph as SVG string.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpipe(\u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msvg\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mSVG_ENCODING)\n","File \u001b[0;32m~/opt/anaconda3/envs/torch_py39/lib/python3.9/site-packages/graphviz/piping.py:104\u001b[0m, in \u001b[0;36mPipe.pipe\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpipe\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     56\u001b[0m          \u001b[39mformat\u001b[39m: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m          renderer: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m          engine: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     62\u001b[0m          encoding: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mUnion[\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the source piped through the Graphviz layout command.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m        '<?xml version='\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe_legacy(\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m    105\u001b[0m                              renderer\u001b[39m=\u001b[39;49mrenderer,\n\u001b[1;32m    106\u001b[0m                              formatter\u001b[39m=\u001b[39;49mformatter,\n\u001b[1;32m    107\u001b[0m                              neato_no_op\u001b[39m=\u001b[39;49mneato_no_op,\n\u001b[1;32m    108\u001b[0m                              quiet\u001b[39m=\u001b[39;49mquiet,\n\u001b[1;32m    109\u001b[0m                              engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    110\u001b[0m                              encoding\u001b[39m=\u001b[39;49mencoding)\n","File \u001b[0;32m~/opt/anaconda3/envs/torch_py39/lib/python3.9/site-packages/graphviz/_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     wanted \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    163\u001b[0m                        \u001b[39mfor\u001b[39;00m name, value \u001b[39min\u001b[39;00m deprecated\u001b[39m.\u001b[39mitems())\n\u001b[1;32m    164\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe signature of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m will be reduced\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    165\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to \u001b[39m\u001b[39m{\u001b[39;00msupported_number\u001b[39m}\u001b[39;00m\u001b[39m positional args\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    166\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(supported)\u001b[39m}\u001b[39;00m\u001b[39m: pass \u001b[39m\u001b[39m{\u001b[39;00mwanted\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39m as keyword arg(s)\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    168\u001b[0m                   stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    169\u001b[0m                   category\u001b[39m=\u001b[39mcategory)\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/opt/anaconda3/envs/torch_py39/lib/python3.9/site-packages/graphviz/piping.py:121\u001b[0m, in \u001b[0;36mPipe._pipe_legacy\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@_tools\u001b[39m\u001b[39m.\u001b[39mdeprecate_positional_args(supported_number\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_pipe_legacy\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    114\u001b[0m                  \u001b[39mformat\u001b[39m: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m                  engine: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    120\u001b[0m                  encoding: typing\u001b[39m.\u001b[39mOptional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m typing\u001b[39m.\u001b[39mUnion[\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe_future(\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m    122\u001b[0m                              renderer\u001b[39m=\u001b[39;49mrenderer,\n\u001b[1;32m    123\u001b[0m                              formatter\u001b[39m=\u001b[39;49mformatter,\n\u001b[1;32m    124\u001b[0m                              neato_no_op\u001b[39m=\u001b[39;49mneato_no_op,\n\u001b[1;32m    125\u001b[0m                              quiet\u001b[39m=\u001b[39;49mquiet,\n\u001b[1;32m    126\u001b[0m                              engine\u001b[39m=\u001b[39;49mengine,\n\u001b[1;32m    127\u001b[0m                              encoding\u001b[39m=\u001b[39;49mencoding)\n","File \u001b[0;32m~/opt/anaconda3/envs/torch_py39/lib/python3.9/site-packages/graphviz/piping.py:149\u001b[0m, in \u001b[0;36mPipe._pipe_future\u001b[0;34m(self, format, renderer, formatter, neato_no_op, quiet, engine, encoding)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m codecs\u001b[39m.\u001b[39mlookup(encoding) \u001b[39mis\u001b[39;00m codecs\u001b[39m.\u001b[39mlookup(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding):\n\u001b[1;32m    148\u001b[0m         \u001b[39m# common case: both stdin and stdout need the same encoding\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipe_lines_string(\u001b[39m*\u001b[39;49margs, encoding\u001b[39m=\u001b[39;49mencoding, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    150\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m         raw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipe_lines(\u001b[39m*\u001b[39margs, input_encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[0;32m~/opt/anaconda3/envs/torch_py39/lib/python3.9/site-packages/graphviz/backend/piping.py:212\u001b[0m, in \u001b[0;36mpipe_lines_string\u001b[0;34m(engine, format, input_lines, encoding, renderer, formatter, neato_no_op, quiet)\u001b[0m\n\u001b[1;32m    206\u001b[0m cmd \u001b[39m=\u001b[39m dot_command\u001b[39m.\u001b[39mcommand(engine, \u001b[39mformat\u001b[39m,\n\u001b[1;32m    207\u001b[0m                           renderer\u001b[39m=\u001b[39mrenderer,\n\u001b[1;32m    208\u001b[0m                           formatter\u001b[39m=\u001b[39mformatter,\n\u001b[1;32m    209\u001b[0m                           neato_no_op\u001b[39m=\u001b[39mneato_no_op)\n\u001b[1;32m    210\u001b[0m kwargs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39minput_lines\u001b[39m\u001b[39m'\u001b[39m: input_lines, \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m: encoding}\n\u001b[0;32m--> 212\u001b[0m proc \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mrun_check(cmd, capture_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, quiet\u001b[39m=\u001b[39;49mquiet, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m proc\u001b[39m.\u001b[39mstdout\n","File \u001b[0;32m~/opt/anaconda3/envs/torch_py39/lib/python3.9/site-packages/graphviz/backend/execute.py:84\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39merrno \u001b[39m==\u001b[39m errno\u001b[39m.\u001b[39mENOENT:\n\u001b[0;32m---> 84\u001b[0m         \u001b[39mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m quiet \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mstderr:\n","\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH"]},{"data":{"text/plain":["<graphviz.graphs.Digraph at 0x7f7a8fa8f490>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# !pip install torchviz\n","from torchviz import make_dot\n","x=torch.tensor([1.],requires_grad=True)\n","# make_dot(x)\n","# make_dot(x**2)\n","# make_dot(x**2+1)\n","make_dot((x**2+1)**2)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kkKQXqM5vPl8"},"source":["## 간단한 인공신경망 만들기"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":283,"status":"ok","timestamp":1676459346735,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"Dmhq1k4fEIKk","outputId":"3d523f27-408f-4788-f97d-be396ddcc333"},"outputs":[{"name":"stdout","output_type":"stream","text":["Linear(in_features=1, out_features=1, bias=True)\n","Parameter containing:\n","tensor([[0.0104]], requires_grad=True)\n","Parameter containing:\n","tensor([-0.7301], requires_grad=True)\n","tensor([-0.7197], grad_fn=<AddBackward0>)\n","tensor([-0.7197], grad_fn=<AddBackward0>)\n"]}],"source":["import torch\n","from torch import nn\n","\n","x = torch.tensor([1.])\n","model = nn.Linear(1,1) # 입력 node 한 개, 출력 node 한 개인 layer 만듦\n","# 채널, 피쳐, 노드 수 다 같은말임!s\n","print(model)\n","\n","print(model.weight) # 만들면서 initialize 함\n","print(model.bias)\n","\n","y=model(x)\n","print(y)\n","\n","y = x @ model.weight + model.bias\n","print(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":307,"status":"ok","timestamp":1676460959807,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"b65wdOXWw4ed","outputId":"0415732e-399e-4bb3-efee-958eab599d20"},"outputs":[{"name":"stdout","output_type":"stream","text":["Parameter containing:\n","tensor([[ 0.5796],\n","        [ 0.3320],\n","        [-0.7347]], requires_grad=True)\n","Parameter containing:\n","tensor([0.6033, 0.7442, 0.7983], requires_grad=True)\n","Parameter containing:\n","tensor([[ 0.5391, -0.0322, -0.4377]], requires_grad=True)\n","Parameter containing:\n","tensor([0.1691], requires_grad=True)\n","tensor([1.1830, 1.0762, 0.0636], grad_fn=<AddBackward0>)\n","tensor([0.7444], grad_fn=<AddBackward0>)\n","tensor([0.7444], grad_fn=<AddBackward0>)\n"]}],"source":["fc1=nn.Linear(1,3) # fully-connected , 1개가 인풋이고 3개가 아웃풋임.\n","fc2=nn.Linear(3,1)\n","\n","print(fc1.weight)\n","print(fc1.bias)\n","print(fc2.weight)\n","print(fc2.bias)\n","\n","x = torch.tensor([1.])\n","x = fc1(x)\n","print(x)\n","x = fc2(x)\n","print(x)\n","\n","x = torch.tensor([1.])\n","y = (x @ fc1.weight.T + fc1.bias) @ fc2.weight.T + fc2.bias\n","# nn.Linear 는 개x채x행x열에서 \"채\" 형태로 (1D data) 들어오길 기대하는 녀석이다 (채널, 피쳐, 노드 수 다 같은말임!)\n","# 즉, 노드 하나가 곧 한 채널의 의미한다.                  \n","# 따라서, 데이터 여러개를 통과시키고 싶다면 개x채 의 형태로 줘야 함\n","\n","# 다른 예시\n","# 3x5 행렬은 개수가 3개, 채널이 5개인 행렬이다. \n","    # 그냥 채널이 5개인 데이터를 3개 가지고 있다는 뜻이다.\n","    # 즉 nn.Linear(5,?) 가 되어야만 한다\n","# 3x5 행렬을 nn.Linear(5,10)에 넣으면 3x10 행렬이 나온다.\n","# 다시, Linear(a,b)는 a개의 채널을 가진 데이터를 b개의 채널로 바꾼다는 뜻이다. \n","\n","# why T? 왜 weight를 transpose 해주지?\n","    # weight 도 개x채 형태로 만들기 위함!!\n","    # 아 input data랑 형태를 맞춰주기 위함!\n","# 일단, weight shape 개x채에서 채는 무조건 앞에 거 채널 개수와 맞추셈!\n","# 예를 들어, nn.Linear(2,3)이면 앞에 거 채널 개수는 2 따라서 ?x2 인데\n","# 두 채널 값을 가지고 3개의 노드를 만드는 거라서 3x2 가 된다!\n","\n","\n","print(y)\n","# input size: 1\n","# fc1.weight.T size: 1x3\n","# fc1.bias size: 3\n","# fc2.weight.T size: 3x1\n","# fc2.bias size: 1"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# 더이상 헷갈리지 말자!\n","# nn.Linear(1,3)은 1개의 채널을 가진 데이터를 3개의 채널로 바꾼다는 뜻이다.\n","x = torch.tensor([[1.],[2.],[3.]]) # 3x1 = 채널이 1개인 데이터 3개\n","x = torch.tensor([[1.,2.,3.]]) # 1x3 = 채널이 3개인 데이터 1개\n","x = torch.tensor([1.,2.,3.]) # 3 = 채널이 3개인 데이터 1개"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1676461057619,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"V0w6q-uj3CRI","outputId":"ec1f4d09-ea72-4dfa-9db5-52adb3e87bfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 0.9580, -0.5387, -0.5935], grad_fn=<AddBackward0>)\n","tensor([0.7850], grad_fn=<AddBackward0>)\n","tensor([0.7850], grad_fn=<AddBackward0>)\n"]}],"source":["fc1=nn.Linear(1,3)\n","fc2=nn.Linear(3,1)\n","\n","x = torch.tensor([1.])\n","x = fc1(x)\n","print(x)\n","x = fc2(x)\n","print(x)\n","\n","model = nn.Sequential(fc1, fc2) # layer 풀칠\n","x = torch.tensor([1.])\n","print(model(x))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":371,"status":"ok","timestamp":1676461633052,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"0W8Cb16W3aQ8","outputId":"f86b8d13-64b2-4597-b9c8-b67910e9cc6f"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([ 0.5511, -0.7286])\n","tensor([ 0.0594,  0.2636, -0.3639], grad_fn=<AddBackward0>)\n","tensor([[-0.3146,  0.0865]])\n","tensor([[-0.1931,  0.1771, -0.1086]], grad_fn=<AddmmBackward0>)\n","tensor([[ 1.3381,  0.0861],\n","        [-1.5835, -1.0218],\n","        [-1.2782,  2.2704],\n","        [ 1.1006, -0.3900],\n","        [-1.0521,  0.4714]])\n","tensor([[ 0.3853,  0.1420, -0.4002],\n","        [-0.7059,  0.3468, -0.0244],\n","        [-0.3950, -0.0835,  0.3364],\n","        [ 0.2727,  0.2083, -0.4182],\n","        [-0.4274,  0.1432,  0.0700]], grad_fn=<AddmmBackward0>)\n","torch.Size([2, 3, 1, 4, 5, 3])\n"]}],"source":["model = nn.Sequential(nn.Linear(2,5), # 여기는 채, 채\n","                      nn.Linear(5,10),\n","                      nn.Linear(10,3))\n","\n","x=torch.randn(2)\n","print(x)\n","print(model(x))\n","\n","x=torch.randn(1,2)\n","print(x)\n","print(model(x))\n","\n","x=torch.randn(5,2) # 개x채 => 두 개의 채널 값(키, 몸무게)을 가지는 데이터(사람) 5개를 통과시킴\n","print(x)\n","print(model(x))\n","\n","x=torch.randn(2,3,1,4,5,2) # 얘가 왜 되는지?\n","print(model(x).shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1676462822324,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"zLiorN8P5mnF","outputId":"b499c548-09f2-4184-b031-6ac5edd0196e"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0.5218, 0.4194, 0.3549],\n","        [0.5205, 0.4182, 0.3569],\n","        [0.5227, 0.4203, 0.3538],\n","        [0.5232, 0.4202, 0.3573],\n","        [0.5234, 0.4210, 0.3544]], grad_fn=<SigmoidBackward0>)\n"]}],"source":["class MyModel(nn.Module):\n","    def __init__(self):  \n","        super().__init__() # nn.Module의 init을 불러옴\n","    # 어떤 layer를 쓸지 정의\n","        self.fc1 = nn.Linear(2,5)\n","        self.fc2 = nn.Linear(5,10)\n","        self.fc3 = nn.Linear(10,3)\n","        self.sig1 = nn.Sigmoid()\n","        self.sig2 = nn.Sigmoid()\n","        self.sig3 = nn.Sigmoid()\n","\n","    # 어떻게 layer를 통과시킬지 정의\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.sig1(x)\n","        x = self.fc2(x)\n","        x = self.sig2(x)\n","        x = self.fc3(x)\n","        x = self.sig3(x)\n","        return x\n","\n","model = MyModel()\n","x = torch.randn(5,2) # 5개의 데이터, 2개의 채널(피쳐, 노드)\n","y = model(x) # forward 함수가 실행됨, 즉 model.forward(x)가 실행됨\n","print(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1676462822325,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"34XkMszM9v-H","outputId":"61e401d7-7de5-4ba9-b438-fed6c4265fa9"},"outputs":[{"name":"stdout","output_type":"stream","text":["MyModel(\n","  (fc1): Linear(in_features=2, out_features=5, bias=True)\n","  (fc2): Linear(in_features=5, out_features=10, bias=True)\n","  (fc3): Linear(in_features=10, out_features=3, bias=True)\n","  (sig1): Sigmoid()\n","  (sig2): Sigmoid()\n","  (sig3): Sigmoid()\n",")\n","Parameter containing:\n","tensor([[-0.1662, -0.5805],\n","        [-0.5876,  0.4499],\n","        [ 0.3691, -0.3692],\n","        [-0.0203, -0.2419],\n","        [-0.1587,  0.2660]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2232,  0.2224, -0.0344,  0.0513,  0.2333, -0.1718,  0.2732, -0.2634,\n","         0.2561,  0.1983], requires_grad=True)\n"]}],"source":["print(model)\n","print(model.fc1.weight)\n","print(model.fc2.bias)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1676463226481,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"XezDTHgC-I9w","outputId":"0996eede-9bf6-4042-e5ed-e1c04166e7a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0.6307, 0.4130, 0.5773],\n","        [0.6306, 0.4143, 0.5746],\n","        [0.6323, 0.4161, 0.5729],\n","        [0.6320, 0.4145, 0.5760],\n","        [0.6362, 0.4176, 0.5742]], grad_fn=<SigmoidBackward0>)\n"]}],"source":["class MyModel2(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.linear = nn.Sequential(nn.Linear(2,5),\n","                                    nn.Sigmoid(),\n","                                    nn.Linear(5,10),\n","                                    nn.Sigmoid(),\n","                                    nn.Linear(10,3),\n","                                    nn.Sigmoid())\n","\n","    def forward(self, x):\n","        x = self.linear(x)\n","        return x\n","\n","model2 = MyModel2()\n","x = torch.randn(5,2)\n","y = model2(x)\n","print(y)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":579,"status":"ok","timestamp":1676463332004,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"NTNzN7iq_IP7","outputId":"b7015bae-b090-4e50-e4f9-5996446cb898"},"outputs":[{"name":"stdout","output_type":"stream","text":["MyModel2(\n","  (linear): Sequential(\n","    (0): Linear(in_features=2, out_features=5, bias=True)\n","    (1): Sigmoid()\n","    (2): Linear(in_features=5, out_features=10, bias=True)\n","    (3): Sigmoid()\n","    (4): Linear(in_features=10, out_features=3, bias=True)\n","    (5): Sigmoid()\n","  )\n",")\n","Parameter containing:\n","tensor([[-0.6994,  0.0343],\n","        [ 0.2865, -0.1813],\n","        [-0.1061, -0.6090],\n","        [-0.0722,  0.4113],\n","        [-0.0292, -0.5662]], requires_grad=True)\n","Parameter containing:\n","tensor([ 0.2928, -0.1753,  0.2498], requires_grad=True)\n"]}],"source":["# Sequential 쓸때와 안쓸때는 뭐가 다른가?\n","\n","print(model2)\n","print(model2.linear[0].weight)\n","print(model2.linear[-2].bias)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1676463396794,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"XaBDZkUhAFVe","outputId":"c203af63-c616-48ab-d68c-25aa711dbbb6"},"outputs":[{"data":{"text/plain":["Parameter containing:\n","tensor([[ 0.0669, -0.0478,  0.0582,  0.0538,  0.2860],\n","        [ 0.2621, -0.2179, -0.3110, -0.0766,  0.1181],\n","        [-0.0839, -0.1444,  0.4449, -0.3039, -0.0053],\n","        [ 0.0075,  0.1255, -0.3866,  0.1172, -0.1234],\n","        [-0.4317,  0.1978, -0.4307,  0.3425, -0.3454],\n","        [-0.1497,  0.3999,  0.2230,  0.0851,  0.3291],\n","        [-0.1460, -0.4230,  0.0039, -0.0530, -0.1694],\n","        [-0.3315,  0.3047, -0.0563,  0.3222,  0.2541],\n","        [ 0.3212, -0.3409,  0.3902, -0.4376,  0.1413],\n","        [-0.2126, -0.1242,  0.0035, -0.2435, -0.0093]], requires_grad=True)"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["list(model.parameters())[2]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":297,"status":"ok","timestamp":1676463502492,"user":{"displayName":"혁펜하임","userId":"13709511177929718136"},"user_tz":-540},"id":"RiXEDsUNAVP2","outputId":"8ed5c765-2d31-47d6-ae3d-39999d236ef6"},"outputs":[{"name":"stdout","output_type":"stream","text":["108\n"]}],"source":["# 파라미터 수 구하기\n","num = sum([p.numel() for p in model.parameters() if p.requires_grad])\n","print(num)"]},{"cell_type":"markdown","metadata":{"id":"6ZdzbQolAxMs"},"source":["## weight initialization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xd6DqcQlAvC8"},"outputs":[],"source":["# 내 필기용 : He initialization 이 공식 문서랑 다르다? => paper에 맞게 구현됐고 torch 공식 문서만 틀림\n","import torch\n","from torch import nn\n","Fin=5000\n","Fout=1000\n","w = torch.zeros(141, Fin)\n","nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu') # forward pass에서 값의 범위를 유지시켜주기 위함\n","print(w.std())\n","print(torch.sqrt(torch.tensor(2/Fin)))\n","w = torch.zeros(Fout, 212)\n","nn.init.kaiming_uniform_(w, mode='fan_out', nonlinearity='relu') # backward pass에서 값의 범위를 유지시켜주기 위함\n","print(w.std())\n","print(torch.sqrt(torch.tensor(2/Fout)))\n","\n","# CNN?\n","N=32\n","C=64\n","H=6\n","W=10\n","w = torch.zeros(N,C,H,W)\n","nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu')\n","print(w.std())\n","print(torch.sqrt(torch.tensor(2/(C*H*W))))\n","\n","w = torch.zeros(N,C,H,W)\n","nn.init.kaiming_uniform_(w, mode='fan_out', nonlinearity='relu')\n","print(w.std())\n","print(torch.sqrt(torch.tensor(2/(N*H*W))))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOP4e2j+l5576sAmwF1wSvy","provenance":[{"file_id":"1XTYOVuYjrMJRP2-BMCB4dTw16uTGYrrH","timestamp":1676286518348}]},"kernelspec":{"display_name":"torch_py39","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"vscode":{"interpreter":{"hash":"0a8cd1283e406caf9791478f1019379e4a48752a34ff0c8cfc8800468c4e1f3f"}}},"nbformat":4,"nbformat_minor":0}
