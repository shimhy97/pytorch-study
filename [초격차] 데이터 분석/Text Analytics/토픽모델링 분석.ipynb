{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"latex_metadata":{"author":"이기황","coursetitle":"텍스트분석기법","courseyear":"2018","date":"2018.04.18","logofile":"figs/ewhauniv-logo.png","logoraise":"-.2","logoscale":".4","title":"단어 임베딩과 토픽 모델링"},"colab":{"name":"토픽모델링 분석.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"AmmNS2vElWYJ"},"source":["# 토픽모델링을 통한 키워드 분석"]},{"cell_type":"markdown","metadata":{"id":"W2JwRFatlWYM"},"source":["## **현재 코드를 제대로 활용하시려면 Chrome으로 실행시켜주세요! **"]},{"cell_type":"code","metadata":{"id":"dtrt4Z58uMfx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625564766995,"user_tz":-540,"elapsed":22982,"user":{"displayName":"김용담","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcMg-SIyaynrayukkEBNN1b6rWweb-FXMnH7MT_xI=s64","userId":"17630601608777393913"}},"outputId":"705ca95d-053b-45fe-e091-81b057dbb2d3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"etv4jsqDlWYP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625564885420,"user_tz":-540,"elapsed":94617,"user":{"displayName":"김용담","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcMg-SIyaynrayukkEBNN1b6rWweb-FXMnH7MT_xI=s64","userId":"17630601608777393913"}},"outputId":"d5db3ac3-d4ec-4fb8-ac51-a81906c5b2b9"},"source":["# 수집한 데이터들중 원하는 가져오기 위해 키워드를 입력합니다.\n","query_keyword = input(\"분석을 위한 키워드를 입력하세요 : \")\n","start, end, step = [int(x) for x in input(\"원하는 토픽 갯수들을 입력하세요(e.g. 2,5,1)\").split(\",\")]"],"execution_count":2,"outputs":[{"output_type":"stream","text":["분석을 위한 키워드를 입력하세요 : 문화\n","원하는 토픽 갯수들을 입력하세요(e.g. 2,5,1)2,10,1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iPMH7vSDlWYP"},"source":["import pickle\n","base_path = \"/content/drive/MyDrive/Colab Notebooks/dataset/\"\n","\n","with open(base_path + f\"tokenized_docs({query_keyword}).pk\", \"rb\") as f:\n","    tokenized_docs = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nrSK34KtlWYN"},"source":["!pip install pyldavis==3.2.2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c-a7YZFKlWYO"},"source":["import sys\n","from sklearn.feature_extraction.text import CountVectorizer\n","from tqdm import tqdm_notebook # progress bar\n","\n","import numpy as np\n","import pandas as pd\n","import string\n","import re\n","import warnings\n","import matplotlib.pyplot as plt\n","import platform\n","from matplotlib import font_manager, rc\n","%matplotlib inline\n","\n","## 운영체제별 글꼴 세팅\n","# 그래프를 이쁘게 그리기 위한 코드입니다. 한글 글꼴을 추가합니다.\n","\n","%matplotlib inline  \n","\n","import matplotlib as mpl  # 기본 설정 만지는 용도\n","import matplotlib.pyplot as plt  # 그래프 그리는 용도\n","import matplotlib.font_manager as fm  # 폰트 관련 용도\n","import seaborn as sns\n","mpl.rcParams['axes.unicode_minus'] = False\n","\n","sys_font=fm.findSystemFonts()\n","print(f\"sys_font number: {len(sys_font)}\")\n","print(sys_font)\n","\n","nanum_font = [f for f in sys_font if 'Nanum' in f]\n","print(f\"nanum_font number: {len(nanum_font)}\")\n","\n","!apt-get update -qq\n","!apt-get install fonts-nanum* -qq\n","\n","path = '/usr/share/fonts/truetype/nanum/NanumBarunGothicBold.ttf'  # 설치된 나눔글꼴중 원하는 녀석의 전체 경로를 가져옵니다.\n","font_name = fm.FontProperties(fname=path, size=10).get_name()\n","print(font_name)\n","plt.rc('font', family=font_name)\n","\n","# 현재 설정되어 있는 폰트 사이즈와 글꼴을 알아보자\n","!python --version\n","def current_font():\n","  print(f\"설정 폰트 글꼴: {plt.rcParams['font.family']}, 설정 폰트 사이즈: {plt.rcParams['font.size']}\")  # 파이썬 3.6 이상 사용가능하다\n","        \n","current_font()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jUjIayTpvHzO"},"source":["# 여전히 글꼴이 보이지 않는 분들은, 런타임 -> \"다시 시작 및 모두 실행\" 을 눌러주세요!\n","fm._rebuild()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"foo72kwclWYS"},"source":["### gensim LDA model을 사용하기 위한 자료구조 생성. "]},{"cell_type":"code","metadata":{"id":"Q4KNJmfVlWYS"},"source":["# 토픽모델링을 위한 라이브러리 불러오기\n","from gensim import corpora\n","from gensim import models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CbmEaAyZlWYS"},"source":["# 문서-단어 행렬 만들기 # LDA의 input.\n","# 어휘(vocabulary) 학습\n","dictionary = corpora.Dictionary(tokenized_docs)\n","# 문서-단어 행렬 생성\n","corpus = [dictionary.doc2bow(document) for document in tokenized_docs]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YBW9yXKHlWYT"},"source":["NUM_TOTAL_WORDS = len(dictionary)\n","print(dictionary)\n","print(NUM_TOTAL_WORDS)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qic1w2ZUlWYU"},"source":["## 3. 토픽 모델링(LDA Model)"]},{"cell_type":"code","metadata":{"id":"MgD8hIVRlWYU"},"source":["# gensim에서 ldamodel 불러오기\n","from gensim.models import ldamodel\n","# lda를 측정하는 지표인 coherence score 계산\n","from gensim.models import CoherenceModel\n","\n","from time import time\n","import os\n","import gensim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"xD3Q0J1UlWYV"},"source":["# 토픽 개수와 토픽 별 상위 추출 단어 개수 지정.\n","NUM_TOPIC_WORDS = 15\n","\n","\n","def build_doc_term_mat(documents):\n","    \"\"\"주어진 문서 집합으로 문서-어휘 행렬을 만들어 돌려준다.\"\"\"\n","    \n","    print_log_msg(\"Building document-term matrix.\")\n","    dictionary = corpora.Dictionary(documents)\n","    corpus = [dictionary.doc2bow(document) for document in documents]\n","\n","    return corpus, dictionary\n","\n","\n","def print_topic_words(model): # model <- (학습이 완료된)ldamodel\n","    \"\"\"토픽별 토픽 단어들을 화면에 인쇄한다.\"\"\"\n","    \n","    print_log_msg(\"Printing topic words.\")\n","    \n","    \n","    for topic_id in range(model.num_topics):\n","        #model.show_topic(0, 15) -> 0번 토픽에서 상위 15개의 단어를 출력해라.\n","        # -> (단어, 확률)을 원소로 하는 리스트 반환.\n","        #model.show_topic(1, 30) -> 1번 토픽에서 상위 30개의 단어를 출력해라.\n","        topic_word_probs = model.show_topic(topic_id, NUM_TOPIC_WORDS)\n","        print(\"Topic ID: {}\".format(topic_id))\n","\n","        for topic_word, prob in topic_word_probs:\n","            print(\"\\t{}\\t{}\".format(topic_word, prob))\n","\n","        print(\"\\n\")\n","\n","\n","def print_log_msg(msg):\n","    \"\"\"로그 메시지를 출력한다.\"\"\"\n","    \n","    print(msg, flush=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g2AdxKqklWYV"},"source":["def compute_coherence(dictionary, corpus, texts, start=8, end=81, step=4):\n","    coherence_score_list = []\n","    model_list = []\n","    # 토픽개수를 2부터 10까지 하고 싶다. -> range(2, 11, 1)\n","    for num_topics in tqdm_notebook(range(start, end, step)):\n","        # LDA model 학습코드\n","        \n","        model = gensim.models.ldamodel.LdaModel(corpus=corpus, # document-term matrix\n","                                               num_topics=num_topics, # 토픽개수(K)\n","                                               id2word=dictionary,\n","                                               passes=30)\n","        \n","        model_list.append(model)\n","        \n","        # Coherence Score 학습 코드\n","        coherence_model = CoherenceModel(model=model,\n","                                        texts=texts,\n","                                        dictionary=dictionary,\n","                                        coherence='c_v')\n","        coherence_score_list.append(coherence_model.get_coherence())\n","        \n","    return model_list, coherence_score_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"sOvReQkJlWYV"},"source":["corpus, dictionary = build_doc_term_mat(tokenized_docs)\n","print(len(corpus), len(dictionary))\n","\n","\n","# 주어진 토픽 개수들에 대해 LDA model, Coherence model 학습\n","model_list, coherence_scores = compute_coherence(dictionary=dictionary,\n","                                                corpus=corpus,\n","                                                texts=tokenized_docs,\n","                                                start=start,\n","                                                end=end,\n","                                                step=step)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p_boPVY8lWYW"},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","\n","coherence_list = coherence_scores\n","label = \"Coherenece Score(C_V)\"\n","\n","x = range(start, end, step)\n","plt.figure(figsize=(16, 12))\n","plt.xticks(x)\n","plt.plot(x, coherence_list, label=label)\n","plt.scatter(x, coherence_list)\n","plt.title(f\"Coherence Scores for LDA with KCI Paper\")\n","plt.xlabel(\"Num Topics\")\n","plt.ylabel(\"Coherence Score\")\n","plt.legend(loc='best')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cjA7H1YWlWYW"},"source":["# 학습한 LDA 모델중에 가장 coherence score가 높은 모델을 선정\n","# model_list, coherence_list는 여러개의 토픽에 대해서 학습한 모델과 cs를 저장하고 있는 리스트.\n","# np.argmax는 리스트의 최대값을 가지는 원소의 index를 return.\n","# e.g. start,end,step = (2,5,1) -> 2,3,4  -> [0, 1, 2]\n","# 만약에 K=4일 때 베스트라면, np.argmax는 2.\n","selected_model = model_list[np.argmax(coherence_list)]\n","selected_model.num_topics"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A_g406MZlWYX"},"source":["### pyLDAvis를 이용한 시각화 "]},{"cell_type":"code","metadata":{"scrolled":false,"id":"YNmiyN_ulWYX"},"source":["# pyLDAvis 불러오기\n","import pyLDAvis.gensim\n","\n","# pyLDAvis를 jupyter notebook에서 실행할 수 있게 활성화.\n","pyLDAvis.enable_notebook()\n","\n","# pyLDAvis 실행.\n","data = pyLDAvis.gensim.prepare(selected_model, corpus, dictionary)\n","data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N9yluW0blWYX"},"source":[""],"execution_count":null,"outputs":[]}]}